<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop</title>
    <url>/2022/03/03/Hadoop/</url>
    <content><![CDATA[<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><ul>
<li>HDFS优缺点：</li>
</ul>
<p>优点：高容错性，适合大规模数据处理，廉价成本</p>
<p>缺点：不适合低延时数据访问，无法高效对大量小文件存储，不支持并发写入，文件随即修改。</p>
<ul>
<li>HDFS组成架构</li>
</ul>
<p>NameNode:管理HDFS名称空间，配置副本策略，管理数据块，处理客户端请求</p>
<p>DataNode:存储实际数据块，执行数据块的读写操作，</p>
<p>Client:文件切分，与NameNode交互获取文件位置信息，与DataNode交互，读写数据</p>
<p>SecondaryNameNode:辅助NameNode为其分担工作量，辅助恢复NameNode</p>
<ul>
<li>Hadoop文件块大小默认为128M</li>
</ul>
<p>文件块太小，会增加寻址时间</p>
<p>文件块太大，从磁盘传输数据的时间将大于定位数据块起始位置所需的时间，导致程序处理数据慢</p>
<ul>
<li>HDFS写数据</li>
</ul>
<ol>
<li>Client向NameNode请求上传文件</li>
<li>NameNode返回是否可以上传</li>
<li>Client请求第一个Block上传到那个DataNode</li>
<li>NameNode返回3个DataNode节点</li>
<li>Client请求datanode1上传数据，datanode1收到请求会继续调用datanode2，datanode2调用datanode3，将通信管道建立完</li>
<li>datanode1，2，3逐级应答Client</li>
<li>Client向datanode1上传第一个Block(Packet)，先从磁盘读数据放到本地进行缓存，datanode1收到一个Packet就会传给datanode2，datanode2传给datanode3，</li>
<li>当一个Block传输完，Client再次请求上传第二个Block</li>
</ol>
<ul>
<li>HDFS读数据</li>
</ul>
<ol>
<li>Client向NameNode请求下载文件，NameNode查询元数据，定位文件块所在DataNode地址</li>
<li>从(先就近后随机)DataNode请求读取数据</li>
<li>DataNode传输数据给Client(Packet)</li>
<li>Client(Packet)接受，先本地缓存后写入目标文件</li>
</ol>
<ul>
<li>NameNode和SecondaryNameNode工作机制</li>
</ul>
<p>NameNode启动：</p>
<ol>
<li>首次启动格式化，创建Fsimage，Edits，之后启动load edits和fsimage到内存</li>
<li>Client对元数据进行增删改请求</li>
<li>NameNode记录操作日志</li>
<li>NameNode在内存中对数据增删改</li>
</ol>
<p>SecondaryNode工作：</p>
<ol>
<li>2NN询问NN是否要CheckPoint</li>
<li>2NN请求执行CheckPoint</li>
<li>NN滚动正在写的Edits，将滚动前的edits和fsimage拷贝到2NN</li>
<li>2NN加载edits和fsimage到内存，并进行合并，生成新的fsimage.checkpoint</li>
<li>拷贝fsimage.checkpoint到NN，NN将fsimage.checkpoint更名为fsimage</li>
</ol>
<ul>
<li>DataNode工作机制</li>
</ul>
<ol>
<li>一个数据块在DataNode上以文件形式存储在磁盘，分别是数据本身和元数据(数据块长度，数据块校验和，时间戳)</li>
<li>DataNode启动后向NameNode注册，通过后周期性(1h)向NameNode上报所有块信息</li>
<li>心跳3s/次，心跳返回结果带有NameNode给DataNode的命令，若超过10min没有收到某个DataNode的心跳，则认为节点已挂</li>
<li>集群运行中可以服役新节点或退役旧节点</li>
</ol>
<ul>
<li>DataNode保证数据完整性</li>
</ul>
<ol>
<li>当DataNode读取Block，会计算CheckSum</li>
<li>若计算后的CheckSum与Block创建时值不同，说明Block已损</li>
<li>Client读取其他DataNode上的Block，DataNode在其文件创建后周期验证CheckSum</li>
</ol>
<ul>
<li>HDFS HA高可用</li>
</ul>
<p>HA即高可用(7*24不间断服务)</p>
<p>实现高可用最关键的策略是消除单点故障，通过配置Active/Standby两个NameNodes实现集群中对NameNode的热备</p>
<h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><ul>
<li>MapReduce优缺点</li>
</ul>
<p>优点：易于编程，良好扩展性，高容错性，适合PB级以上海量数据离线处理</p>
<p>缺点：不擅长实时计算，不擅长流式计算，不擅长DAG计算</p>
<ul>
<li>MapReduce核心思想</li>
</ul>
<ol>
<li>分布式的计算通常要分为至少两个阶段</li>
<li>第一阶段的MapTask并发实例，完全并行运行</li>
<li>第二阶段的ReduceTask并发实例互不相干，但数据依赖于上个阶段所有MapTask并发实例的输出</li>
<li>MapReduce编程模型只能包含一个Map和Reduce阶段</li>
</ol>
<ul>
<li>Shuffle机制</li>
</ul>
<ol>
<li>Collect阶段：MapTask的数据输出到环形缓冲区</li>
<li>Spill阶段：当内存中数据量到一定阈值，会将数据写入本地磁盘(将数据写入磁盘前需要对数据进行一次排序)，如果配置combiner会将相同分区号和key的数据进行排序</li>
<li>MapTask阶段的Merge：把所有溢出的临时文件进行一次merge，确保一个MapTask最终只产生一个中间数据文件</li>
<li>Copy阶段：ReduceTask启动Fetcher线程到已完成MapTask节点上copy一份数据</li>
<li>ReduceTask阶段的Merge：在ReduceTask复制数据同时，会在后台开启两个线程对内存到本地的数据文件进行merge</li>
<li>Sort阶段：对数据进行merge同时，会进行排序，由于MapTask阶段已经对数据进行了局部排序，ReduceTask只需保证Copy数据的最终整体有效性</li>
</ol>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark</title>
    <url>/2022/03/04/Spark/</url>
    <content><![CDATA[<blockquote>
<p>Spark大数据的计算分析引擎</p>
</blockquote>
]]></content>
      <tags>
        <tag>数据</tag>
      </tags>
  </entry>
</search>
