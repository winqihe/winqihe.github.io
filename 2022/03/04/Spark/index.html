

<!DOCTYPE html>
<html lang="zh-CN" >



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avator.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Keven He">
  <meta name="keywords" content="大数据开发,Spark,Flink,Kafka">
  
    <meta name="description" content="Spark大数据的计算分析引擎  官网 https:&#x2F;&#x2F;spark.apache.org&#x2F;   本文摘录于《Spark大数据处理技术》">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark">
<meta property="og:url" content="http://example.com/2022/03/04/Spark/index.html">
<meta property="og:site_name" content="WenQi&#96;s Blog">
<meta property="og:description" content="Spark大数据的计算分析引擎  官网 https:&#x2F;&#x2F;spark.apache.org&#x2F;   本文摘录于《Spark大数据处理技术》">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h02j0862b7j30ky04ijrl.jpg">
<meta property="og:image" content="https://tva2.sinaimg.cn/large/0082w7mmly8h02j2w0ltxj30mu092mxt.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h02j5gw5b9j30pg047t90.jpg">
<meta property="og:image" content="https://tva2.sinaimg.cn/large/0082w7mmly8h02jiomgszj30lh0ckdgp.jpg">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h02jtb7ww4j30ki05jt96.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h02kef8mpbj30hr0cmq3c.jpg">
<meta property="og:image" content="https://tva2.sinaimg.cn/large/0082w7mmly8h02kewzqs2j30ik07cweq.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h02nqgxyjwj3084071mx8.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h03z89yka2j30ds06zgm0.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h03zhvod2yj30jb0a1gm9.jpg">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h03zi7zjjdj30i90bkgmn.jpg">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h03zoa22rzj30ne05eaau.jpg">
<meta property="og:image" content="https://tva2.sinaimg.cn/large/0082w7mmly8h03znoilg5j30kd09k3zc.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h03xgwdkm8j30hp06adg2.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h03y9juahsj30n80cnmz7.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h03yah7hklj30ny092q3o.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082w7mmly8h03yisqxnfj30n109rgmk.jpg">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h04s6ljwgfj30pl08pmxw.jpg">
<meta property="og:image" content="https://tva3.sinaimg.cn/large/0082w7mmly8h04s9jnhcij30hv04zq32.jpg">
<meta property="og:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h04sd4t22lj30pe083mxw.jpg">
<meta property="article:published_time" content="2022-03-04T13:01:52.000Z">
<meta property="article:modified_time" content="2022-03-10T07:17:33.865Z">
<meta property="article:author" content="Keven He">
<meta property="article:tag" content="数据 Spark">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://tva4.sinaimg.cn/large/0082w7mmly8h02j0862b7j30ky04ijrl.jpg">
  
  
  <title>Spark - WenQi`s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>KevenHe</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                archive
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                category
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                tag
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                about
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/background.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Spark"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
  </div>

  <div class="mt-1">
    

    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Spark</h1>
            
            <div class="markdown-body">
              
              <blockquote>
<p>Spark大数据的计算分析引擎  官网 <a target="_blank" rel="noopener" href="https://spark.apache.org/">https://spark.apache.org/</a></p>
</blockquote>
<ul>
<li>本文摘录于《Spark大数据处理技术》</li>
</ul>
<span id="more"></span>

<h4 id="Spark概述"><a href="#Spark概述" class="headerlink" title="Spark概述"></a><strong>Spark概述</strong></h4><blockquote>
<p>Apache Spark is a unified analytics engine for large-scale data processing</p>
</blockquote>
<p>按照现在流行的大数据处理场景划分，可以将大数据处理分为三种情况：</p>
<ul>
<li>复杂的批量数据处理，通常时间跨度为数十分钟到数小时</li>
<li>基于历史数据的交互式查询，通常时间跨度为数十秒到数分钟</li>
<li>基于实时数据流的数据处理，通常时间跨度为数百毫秒到数秒</li>
</ul>
<p>在Spark Core基础上衍生出能同时处理上面三种情形的统一大数据处理平台</p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h02j0862b7j30ky04ijrl.jpg" srcset="/img/loading.gif" lazyload></p>
<p>Spark要做的是将批处理，交互式处理，流式处理融合到一个软件栈中</p>
<p><img src="https://tva2.sinaimg.cn/large/0082w7mmly8h02j2w0ltxj30mu092mxt.jpg" srcset="/img/loading.gif" lazyload></p>
<h4 id="Spark-RDD及编程接口"><a href="#Spark-RDD及编程接口" class="headerlink" title="Spark RDD及编程接口"></a>Spark RDD及编程接口</h4><p><strong>HelloWorld</strong></p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h02j5gw5b9j30pg047t90.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>对于Spark程序来讲，所有的操作的前提是要有一个Spark上下文，创建上下文过程中，程序会向集群申请资源并构建运行环境。</li>
<li>通过sc变量并利用textFile接口从HDFS文件系统读取文件，返回file变量</li>
<li>对file进行过滤操作，生成新的变量filterRDD</li>
<li>对filterRDD进行cache操作(方便重用filterRDD)</li>
<li>对filterRDD进行计数，返回结果</li>
</ul>
<p>这个程序中涉及到众多概念：</p>
<ul>
<li>弹性式分布式数据集 RDD</li>
<li>创建操作(creation operation)：RDD初始创建是SparkContext负责，将内存集合或外部文件系统作为输入源</li>
<li>转换操作(transformation operation)：将一个RDD通过一定操作转变为另一个RDD</li>
<li>控制操作(control operation)：对RDD进行持久化，让RDD保存磁盘或内存中，方便重复使用</li>
<li>行动操作(action operation)：Spark是惰性计算的，RDD所有行动操作，都会触发Spark作业运行</li>
</ul>
<p>RDD和操作之间关系：经过输入操作，转换操作，控制操作，输出操作来完成一个作业</p>
<p><img src="https://tva2.sinaimg.cn/large/0082w7mmly8h02jiomgszj30lh0ckdgp.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>Spark RDD</strong></p>
<p>RDD是弹性分布式数据集，即一个RDD代表一个被分区的只读数据集，RDD有两种生成途径：来自内存集合和外部存储系统；通过RDD的转换操作</p>
<p>RDD继承关系(lineage)构建可以通过记录作用在RDD上的转换操作，可以有效进行容错处理</p>
<p>一般情况下抽象的RDD需要包含这五个接口</p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h02jtb7ww4j30ki05jt96.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>RDD分区(partitions)</strong></p>
<p>对于RDD来说，分区数涉及到RDD进行并行计算的粒度，每一个RDD分区的计算操作都在一个单独的任务中被执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd = sc.parallelize(1 to 100,2)</span><br><span class="line">//1-100的数组转为RDD，第二个参数执行分区数</span><br><span class="line">rdd.partitions.size</span><br><span class="line">//查看RDD被划分的分区数</span><br></pre></td></tr></table></figure>

<p><strong>RDD优先位置(preferredLocations)</strong></p>
<p>RDD优先位置属性与Spark中的调度相关，返回的是RDD的每个partition存储的位置，“移动数据不如移动计算”所以Spark任务调度时候尽可能将任务分配到数据块存储位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val rdd = sc.textFile(&quot;hdfs://10.0.2.19:8000/bigfile&quot;)</span><br><span class="line">//读取bigfile生成rdd</span><br><span class="line">val hadoopRDD =rdd.dependencies(0).rdd</span><br><span class="line">//通过rdd依赖关系找到原始hadoopRDD</span><br><span class="line">hadoopRDD.partitions.size</span><br><span class="line">hadoopRDD.preferredLocations(hadoopRDD.partition(0))</span><br><span class="line">//返回partition(0)所在的机器位置</span><br></pre></td></tr></table></figure>

<p><strong>RDD依赖关系(dependencies)</strong></p>
<p>由于RDD是粗粒度操作数据集，每个转换操作都会生成一个新的RDD，所以RDD之间会形成类似流水线(pipline)的前后依赖关系，Spark中有两种类型依赖。</p>
<p>窄依赖(Narrow Dependencies)：每一个父RDD的分区最多只能被子RDD的一个分区使用</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h02kef8mpbj30hr0cmq3c.jpg" srcset="/img/loading.gif" lazyload></p>
<p>宽依赖(Wide Dependencies)：多个子RDD的分区会依赖于同一个父RDD的分区</p>
<p><img src="https://tva2.sinaimg.cn/large/0082w7mmly8h02kewzqs2j30ik07cweq.jpg" srcset="/img/loading.gif" lazyload></p>
<p>Spark中明确区分宽窄依赖原因？</p>
<ol>
<li>窄依赖可以在集群的一个节点上如流水线一样执行，可以计算所有父RDD分区，相反宽依赖需要取得父RDD的所有分区上的数据进行计算，将执行类似MapReduce一样的Shuffle操作</li>
<li>对于窄依赖，节点计算失败后恢复会更有效，只需重新计算对应父RDD的分区，而且可以在其他节点上并行的计算，相反在宽依赖依赖关系中，一个节点失败会导致其父RDD的多个分区重新计算</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd =sc.makeRDD(1 to 10)</span><br><span class="line">val mapRDD= rdd.map(x=&gt;(x,x))</span><br><span class="line">mapRDD.dependencies</span><br><span class="line">val shuffleRDD = mapRDD.partitionBy(new org.apache.spark.HashPartitioner(3))</span><br><span class="line">shuffleRDD.dependencies</span><br></pre></td></tr></table></figure>

<p><strong>RDD分区计算(compute)</strong></p>
<p>RDD的计算都是以partition为单位的，而且RDD中的compute函数都是在对迭代器进行复合，不需要保存每次计算结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">val rdd = sc.parallelize(1 to 10,2)</span><br><span class="line">val map_rdd = rdd.map(a=&gt;a+1)</span><br><span class="line">val filter_rdd = map_rdd.filter(a=&gt;(a&gt;3))</span><br><span class="line">val context = new org.apache.spark.TaskContext(0,0,0)</span><br><span class="line">val iter0 = filter_rdd.compute(filter_rdd.partition(0),context)</span><br><span class="line">iter0.toList</span><br><span class="line">val iter1 = filter_rdd.compute(filter_rdd.partition(0),context)</span><br><span class="line">iter1.toList</span><br><span class="line">//在rdd上进行map和filter，由于compute函数只返回相应分区数据的迭代器，只有最后实例化才能显示出两个分区最终计算结果</span><br></pre></td></tr></table></figure>

<p><strong>RDD分区函数(partitioner)</strong></p>
<p>Spark目前有两种类型分区函数：HashPartitioner(哈希分区)和RangePartitioner(区域分区)，而且partitioner这个属性只存在于(K,V)类型的RDD中，对于非(K,V)类型的partitioner的值就是None，partitioner函数既决定了RDD本身的分区数量，也可作为其父RDD Shuffle输出(MapOutput)中每个分区进行数据切割的依据</p>
<p>使用HashPartitioner说明一下partitioner的功能</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val rdd =sc.makeRDD(1 to 10,2).map(x=&gt;(x,x))</span><br><span class="line">rdd.partitioner</span><br><span class="line">val group_rdd = rdd.groupByKey(new org.apache.spark.HashPartitioner(3))</span><br><span class="line">//new 了HashPartitioner对象</span><br><span class="line">group_rdd.partitioner</span><br><span class="line">group_rdd.collectPartitions()</span><br></pre></td></tr></table></figure>

<p>HashPartitioner的原理图：</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h02nqgxyjwj3084071mx8.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>集合创建操作</strong></p>
<p>RDD的创建可由内部集合类型来生成，Spark提供了parallelize和makeRDD两类函数实现从集合生成RDD，但makeRDD中提供了一个可以指定每一个分区preferredLocations参数的实现版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val rdd = sc.makeRDD(1 to 10,3)</span><br><span class="line">rdd.collectPartitions()</span><br><span class="line">val collect = Seq(1 to 10,Seq(&quot;host1&quot;,&quot;host3&quot;)),(11 to 20, Seq(&quot;host2&quot;)))</span><br><span class="line">val rdd =sc.makeRDD(collect)</span><br><span class="line">rdd.preferreedLocations(rdd.partitions(0))</span><br><span class="line">rdd.preferredLocations(rdd.partitions(1))</span><br></pre></td></tr></table></figure>

<p><strong>存储创建操作</strong></p>
<p>主要是hadoopRDD和newHadoopRDD两个编程接口，包含了四个参数(输入格式；键类型；值类型；分区值)</p>
<p><strong>转换操作(transformation operation)</strong></p>
<table>
<thead>
<tr>
<th align="left">Transformation</th>
<th align="left">Meaning</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>map</strong>(<em>func</em>)</td>
<td align="left">将处理的数据逐条进行映射转换(类型或值)</td>
</tr>
<tr>
<td align="left"><strong>filter</strong>(<em>func</em>)</td>
<td align="left">将数据根据指定的规则进行筛选过滤</td>
</tr>
<tr>
<td align="left"><strong>flatMap</strong>(<em>func</em>)</td>
<td align="left">将处理的数据进行扁平化后再进行映射处理</td>
</tr>
<tr>
<td align="left"><strong>mapPartitions</strong>(<em>func</em>)</td>
<td align="left">将待处理的数据以分区为单位发送到计算节点进行处理</td>
</tr>
<tr>
<td align="left"><strong>mapPartitionsWithIndex</strong>(<em>func</em>)</td>
<td align="left">将待处理的数据以分区为单位发送到计算节点进行处理，在处理时同时可以获取当前分区索引。</td>
</tr>
<tr>
<td align="left"><strong>sample</strong>(<em>withReplacement</em>, <em>fraction</em>, <em>seed</em>)</td>
<td align="left">根据指定的规则从数据集中抽取数据</td>
</tr>
<tr>
<td align="left"><strong>union</strong>(<em>otherDataset</em>)</td>
<td align="left">对源 RDD 和参数 RDD 求并集后返回一个新的 RDD</td>
</tr>
<tr>
<td align="left"><strong>intersection</strong>(<em>otherDataset</em>)</td>
<td align="left">对源 RDD 和参数 RDD 求交集后返回一个新的 RDD</td>
</tr>
<tr>
<td align="left"><strong>distinct</strong>([<em>numPartitions</em>]))</td>
<td align="left">将数据集中重复的数据去重</td>
</tr>
<tr>
<td align="left"><strong>groupByKey</strong>([<em>numPartitions</em>])</td>
<td align="left">将数据源的数据根据 key 对 value 进行分组</td>
</tr>
<tr>
<td align="left"><strong>reduceByKey</strong>(<em>func</em>, [<em>numPartitions</em>])</td>
<td align="left">可以将数据按照相同的 Key 对 Value 进行聚合</td>
</tr>
<tr>
<td align="left"><strong>aggregateByKey</strong>(<em>zeroValue</em>)(<em>seqOp</em>, <em>combOp</em>, [<em>numPartitions</em>])</td>
<td align="left">将数据根据不同的规则进行分区内计算和分区间计算</td>
</tr>
<tr>
<td align="left"><strong>sortByKey</strong>([<em>ascending</em>], [<em>numPartitions</em>])</td>
<td align="left">在一个(K,V)的 RDD 上调用，K 必须实现 Ordered 接口(特质)，返回一个按照 key 进行排序的RDD</td>
</tr>
<tr>
<td align="left"><strong>join</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td>
<td align="left">在类型为(K,V)和(K,W)的 RDD 上调用，返回一个相同 key 对应的所有元素连接在一起的 (K,(V,W))的 RDD</td>
</tr>
<tr>
<td align="left"><strong>cogroup</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td>
<td align="left">在类型为(K,V)和(K,W)的 RDD 上调用，返回一个(K,(Iterable,Iterable))类型的 RDD</td>
</tr>
<tr>
<td align="left"><strong>coalesce</strong>(<em>numPartitions</em>)</td>
<td align="left">根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率 当 spark 程序中，存在过多的小任务的时候，可以通过 coalesce 方法，收缩合并分区，减少 分区的个数，减小任务调度成本</td>
</tr>
<tr>
<td align="left"><strong>repartition</strong>(<em>numPartitions</em>)</td>
<td align="left">该操作内部其实执行的是 coalesce 操作，参数 shuffle 的默认值为 true。无论是将分区数多的 RDD 转换为分区数少的 RDD，还是将分区数少的 RDD 转换为分区数多的 RDD，repartition 操作都可以完成，因为无论如何都会经 shuffle 过程。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<p><font color="red">reduceByKey 和 groupByKey 的区别？</font></p>
<p>Shuffle角度：reduceByKey 和 groupByKey 都存在 shuffle 的操作，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行预聚合（combine）功能，这样会减少落盘的 数据量，而 groupByKey 只是进行分组，不存在数据量减少的问题，reduceByKey 性能比较 高。</p>
<p> 功能的角度：reduceByKey 其实包含分组和聚合的功能。GroupByKey 只能分组，不能聚 合，所以在分组聚合的场合下，推荐使用 reduceByKey，如果仅仅是分组而不需要聚合。那 么还是只能使用 groupByKe</p>
<p><strong>控制操作(control operation)</strong></p>
<ul>
<li>cache():RDD[T]</li>
<li>persist():RDD[T]</li>
<li>persist(level:StorageLevel):RDD[T]</li>
</ul>
<p>Spark通过持久化操作将RDD持久化到不同层次的存储介质中，方便重复使用</p>
<ul>
<li>checkpoint</li>
</ul>
<p>checkpoint接口将RDD持久化到HDFS上，于persist(若也存在磁盘上)的区别是checkpoint会切断此RDD之前的依赖关系</p>
<p>checkpoint主要作用：Spark长时间运行，过长的依赖将会耗用大量系统资源，定期将RDD进行checkpoint操作，可有效地节省系统资源；过长的依赖关系会出现节点失败RDD容错重新计算的成本将会大大提升</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val rdd =sc.makeRDD(1 to 4,1)</span><br><span class="line">val flatMapRDD= rdd.flatMap(x=&gt;Seq(x,x))</span><br><span class="line">sc.setCheckpointDir(&quot;temp&quot;)</span><br><span class="line">flatMapRDD.checkpoint()</span><br><span class="line">flatMapRDD.dependencies.head.rdd</span><br><span class="line">flatMapRDD.collect()</span><br><span class="line">flatMapRDD.dependencies.head.rdd</span><br></pre></td></tr></table></figure>



<p><strong>行动操作(action operation)</strong></p>
<p>Spark中触发action operation将会触发一次Spark调度并返回相应结果</p>
<table>
<thead>
<tr>
<th align="left">Action</th>
<th align="left">Meaning</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>reduce</strong>(<em>func</em>)</td>
<td align="left">聚集 RDD 中的所有元素，先聚合分区内数据，再聚合分区间数据</td>
</tr>
<tr>
<td align="left"><strong>collect</strong>()</td>
<td align="left">在驱动程序中，以数组 Array 的形式返回数据集的所有元素</td>
</tr>
<tr>
<td align="left"><strong>count</strong>()</td>
<td align="left">返回 RDD 中元素的个数</td>
</tr>
<tr>
<td align="left"><strong>first</strong>()</td>
<td align="left">返回 RDD 中的第一个元素</td>
</tr>
<tr>
<td align="left"><strong>take</strong>(<em>n</em>)</td>
<td align="left">返回一个由 RDD 的前 n 个元素组成的数组</td>
</tr>
<tr>
<td align="left"><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td>
<td align="left">返回该 RDD 排序后的前 n 个元素组成的数组</td>
</tr>
<tr>
<td align="left"><strong>saveAsTextFile</strong>(<em>path</em>)</td>
<td align="left">将数据保存到不同格式的文件中</td>
</tr>
<tr>
<td align="left"><strong>countByKey</strong>()</td>
<td align="left">统计每种 key 的个数</td>
</tr>
<tr>
<td align="left"><strong>foreach</strong>(<em>func</em>)</td>
<td align="left">分布式遍历 RDD 中的每一个元素，调用指定函数</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="Spark调度管理原理"><a href="#Spark调度管理原理" class="headerlink" title="Spark调度管理原理"></a>Spark调度管理原理</h4><p><strong>调度概述</strong></p>
<p>调度的前期是判断多个作业任务的依赖关系，这些作业任务之间可能存在因果的依赖关系，所以DAG有向无环图来表示这种关系</p>
<p>DAGScheduler负责将作业拆分为不同阶段的具有依赖关系的多批任务，简单理解为任务的逻辑调度</p>
<p>TaskScheduler负责每个具体任务的实际物理调度</p>
<blockquote>
<p>Task：单个分区数据集上最小处理流程单元</p>
<p>TaskSet：由一组关联的但相互间没有Shuffle依赖关系的任务所组成的任务集</p>
<p>Stage：一个任务集对应的调度阶段</p>
<p>Job：由一个RDD action生成的一个或多个调度阶段所组成的一次计算作业</p>
<p>Application：spark应用程序，由一到多个Job组成</p>
</blockquote>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h03z89yka2j30ds06zgm0.jpg" srcset="/img/loading.gif" lazyload></p>
<p>在Spark运行时，这些计算操作是延迟执行的，并不是所有的RDD操作都会触发Spark向集群提交实际作业，只有需要返回数据或输出数据操作才会触发实际计算工作，其他变换操作知识生成对应的RDD关系链，用来记录依赖关系和所需执行的运算；另外DAGScheduler内部维度了各种“任务/调度阶段/作业”的状态和互相之间的映射关系表，用于在任务状态更新，集群状态更新等情况下，正确维护作业运行逻辑</p>
<p><strong>作业调度具体工作流程</strong></p>
<p>每个作业从提交到完成，要经历拆分成任务为最小单位，按一定逻辑依赖关系一次提交执行，并返回结果</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h03zhvod2yj30jb0a1gm9.jpg" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h03zi7zjjdj30i90bkgmn.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>调度任务拆分：</strong></p>
<p>当一个RDD操作触发计算，向DAGScheduler提交作业时，DAGScheduler需要从RDD依赖链末端的RDD触发，遍历整个RDD依赖链，划分调度阶段，并决定各个调度阶段间的依赖关系，调度阶段的划分是以ShuffleDependency为依据。</p>
<p><strong>调度阶段的提交：</strong></p>
<p>在划分调度阶段步骤中会得到一个或多个有依赖关系的调度阶段，其中直接触发作业的RDD关联的调度阶段叫做FinalStage，DAGScheduler进一步从FinalStage生成一个作业实例，两者关系存储在映射表，用于调度阶段全部完成时做一些处理如报告状态，清理作业相关数据等</p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h03zoa22rzj30ne05eaau.jpg" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://tva2.sinaimg.cn/large/0082w7mmly8h03znoilg5j30kd09k3zc.jpg" srcset="/img/loading.gif" lazyload></p>
<p>当一个属于中间过程调度阶段的任务完成后，DAGScheduler会检查对应的调度阶段的所有任务是否都完成了，都完成了将再次扫描一次等待列表中的所有调度阶段的列表，检查是否还有任何依赖的调度阶段未完成，若没有，说明调度阶段处理就绪状态，可以再次尝试提交</p>
<p><strong>任务集的提交</strong></p>
<p>调度阶段的提交，最终会被转换成一个任务集的提交，DAGScheduler通过TaskScheduler接口提交任务集，这个任务集最终会触发TaskScheduler构建一个TaskSetManager的实例来管理这个任务集的生命周期，对于DAGScheduler来说提交调度阶段的工作到此完成，而TaskScheduler的具体实现会在得到资源时，通过TaskSetManager调度具体的任务到对应的Executor节点上进行运算</p>
<h4 id="Spark存储管理"><a href="#Spark存储管理" class="headerlink" title="Spark存储管理"></a>Spark存储管理</h4><p><strong>RDD持久化</strong></p>
<p>分区和数据块的关系：</p>
<p>在操作RDD时，这些操作都将施行在每一个分区上，可以说RDD上的运算都是基于分区的，但在存储管理模块，接触到的是数据块(block)，存储管理模块中对数据的存取都是以数据块为单位的，分区其实是一个逻辑上的概念，而数据块是物理上的数据实体</p>
<p>在Spark中，分区和数据块是一一对应的，存储模块只关心数据块，对于数据块和分区之间的映射是通过名称上的约定进行的，ID号+索引号作为块的名称就建立了分区和块的映射</p>
<p>在显示调用函数缓存RDD时，Spark内部就建立了RDD分区和数据块之间的映射，当读取缓存的RDD时，根据映射关系，就能从存储管理模块中获取到对应的数据块</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h03xgwdkm8j30hp06adg2.jpg" srcset="/img/loading.gif" lazyload></p>
<p>内存缓存：</p>
<p>当Spark基于内存持久化缓存RDD时，RDD中每一个分区对应的数据块都是会被存储管理模块中的内存缓存(Memory Store所管理的)，内存缓存在内部维护了一个以数据块名称为Key，块内容为Value的哈希表</p>
<p><font color="red">当内存不是或达到设置的阈值时如何处理?</font></p>
<p>Spark通过spark.storage.memoryFration来配置(0.6)，JVM内存的60%可被内存缓存用来存储块内容，当占用&gt;60%，spark会丢一些数据块或将一些数据块存储到磁盘上来释放内存缓存空间，若丢掉的RDD 所依赖的父RDD是可被回溯并可用的，是不影响错误恢复机制的</p>
<p>磁盘缓存：</p>
<p>spark会将数据块放到磁盘目录下，通过spark.local.dir就配置了缓存在磁盘的目录</p>
<p>持久化选项：</p>
<p>当需要将RDD持久化，Spark可以调用persist()或cache()函数，对于RDD持久化，Spark提供了多种持久化选项</p>
<ul>
<li>MEMORY_ONLY：RDD以Java对象存储到到JVM内存heap中，超出内存缓存部分将不会缓存，下次需要重新计算</li>
<li>MEMORY_AND_DISK：和MEMORY_ONLY不同点是超出内存缓存部分将存在磁盘，需要将从磁盘读取</li>
<li>MEMORY_ONLY_SER：将序列化后的RDD存储到JVM中，占用空间更小，但读取时候需耗费更多CPU资源进行反序列化</li>
<li>MEMORY_AND_DISK_SER：和MEMORY_ONLY_SER不同是会把内存无法容下分区写入磁盘缓存</li>
<li>DISK_ONLY：将RDD的分区只缓存到磁盘中</li>
</ul>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h03y9juahsj30n80cnmz7.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>Shuffle数据持久化</strong></p>
<p>每一个Map任务会根据Reduce任务的数量创建出相应的桶，桶的数量是M*R。Map任务产生的结果会根据所设置的分区算法填充到每个桶中，当Reduce任务启动时，会根据自己任务ID和所依赖的Map任务的ID从远端或本地存储管理模块中取得相应的桶作为输入处理</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h03yah7hklj30ny092q3o.jpg" srcset="/img/loading.gif" lazyload></p>
<p>和RDD持久化不同的是：首先Shuffle数据块必须在磁盘进行缓存，而不能选择在内存缓存，其次RDD基于磁盘持久化中，每个数据块对应一个文件，在Shuffle数据块持久化中，Shuffle数据块表示的只是逻辑概念，Shuffle有两种存储方式：</p>
<p>一种是将Shuffle数据块映射成文件，另一种是将Shuffle数据块映射成文件中的一段，这种方式要spark.shuffle.consolidateFiles设置为true，这种方式将分时运行的Map任务产生的Shuffle数据块合并到同一个文件中，来减少Shuffle文件的总数</p>
<p><img src="https://tva1.sinaimg.cn/large/0082w7mmly8h03yisqxnfj30n109rgmk.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>广播(Broadcast)变量持久化</strong></p>
<p>为了加速一些对小块数据的读取，最好数据在所有节点都有一份拷贝，每个任务都能从本节点拷贝读取数据而不用通过远程传输获取数据，广播变量实现了这个功能，广播变量由存储管理模块进行管理的，另外广播变量数据块是以MEMORY_AND_DISK持久化存储本节点的存储管理模块，通过设置过期清洗机制，Spark内部会清理过期的广播变量</p>
<h4 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h4><p>用于快速构建可扩展，高吞吐，高容错的流处理程序</p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h04s6ljwgfj30pl08pmxw.jpg" srcset="/img/loading.gif" lazyload></p>
<p>DStream(离散数据流)代表了一个数据流，数据流可从外部输入源获得也可以通过输入流的转换获得，DStream是通过一组时间序列上连续的RDD来表示</p>
<p><img src="https://tva3.sinaimg.cn/large/0082w7mmly8h04s9jnhcij30hv04zq32.jpg" srcset="/img/loading.gif" lazyload></p>
<p><strong>DEMO</strong></p>
<p>获取指定端口上的数据并进行词频统计</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">object NetworkWordCount &#123;</span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]) &#123;</span><br><span class="line"></span><br><span class="line">    /*指定时间间隔为 5s*/</span><br><span class="line">    val sparkConf = new SparkConf().setAppName(&quot;NetworkWordCount&quot;).setMaster(&quot;local[2]&quot;)</span><br><span class="line">    val ssc = new StreamingContext(sparkConf, Seconds(5))</span><br><span class="line"></span><br><span class="line">    /*创建文本输入流,并进行词频统计*/</span><br><span class="line">    val lines = ssc.socketTextStream(&quot;hadoop001&quot;, 9999)</span><br><span class="line">    lines.flatMap(_.split(&quot; &quot;)).map(x =&gt; (x, 1)).reduceByKey(_ + _).print()</span><br><span class="line"></span><br><span class="line">    /*启动服务*/</span><br><span class="line">    ssc.start()</span><br><span class="line">    /*等待服务结束*/</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>nc -lk 9999</code>打开端口写入测试数据</p>
<p>Spark Streaming 编程的入口类是 StreamingContext，在创建时候需要指明 <code>sparkConf</code> 和 <code>batchDuration</code>(批次时间)，Spark 流处理本质是将流数据拆分为一个个批次，然后进行微批处理，<code>batchDuration</code> 就是批次拆分的时间间隔。这个时间可以根据业务需求和服务器性能进行指定，如果业务要求低延迟并且服务器性能也允许，则这个时间可以指定得很短。</p>
<p>DStream 是 Spark Streaming 提供的基本抽象。它表示连续的数据流。在内部，DStream 由一系列连续的 RDD 表示。所以从本质上而言，应用于 DStream 的任何操作都会转换为底层 RDD 上的操作。</p>
<p><img src="https://tva4.sinaimg.cn/large/0082w7mmly8h04sd4t22lj30pe083mxw.jpg" srcset="/img/loading.gif" lazyload></p>
<h4 id="Spark调优"><a href="#Spark调优" class="headerlink" title="Spark调优"></a>Spark调优</h4><p><strong>RDD调优</strong></p>
<ul>
<li>RDD复用</li>
<li>尽早进行filter</li>
<li>读取大量小文件用wholeTextFiles</li>
<li>mapPartition和foreachPartition替代map和foreach操作</li>
<li>filter+coalesce/repartition(减少分区)</li>
<li>设置合理的并行度</li>
<li>repartition/coalesce调节并行度</li>
<li>reduceByKey本地预聚合</li>
<li>使用持久化+checkpoint</li>
<li>使用广播变量使用Kryo序列化</li>
</ul>
<p><strong>Shuffle调优</strong></p>
<ul>
<li>map和reduce端缓冲区大小</li>
<li>reduce端重试次数和等待时间间隔</li>
<li>bypass机制开启阈值</li>
</ul>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%95%B0%E6%8D%AE-Spark/">#数据 Spark</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Spark</div>
      <div>http://example.com/2022/03/04/Spark/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Keven He</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年3月4日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/03/05/Kafka/" title="Kafka">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kafka</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/03/03/Hadoop/" title="Hadoop">
                        <span class="hidden-mobile">Hadoop</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
